<!DOCTYPE html>

<html>

<head>
    <style>
        td,
        th {
            border: 0px solid black;
        }

        img {
            padding: 5px;
        }
    </style>

    <title>FaceXFormer</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="shortcut icon" href="./static/images/jhu_web.png" />

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
    <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"> <i>FaceXFormer</i> : A Unified Transformer <br> for
                            Facial
                            Analysis
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Group of first four authors -->
                            <div class="authors-group">
                                <span class="author-block">
                                    <a href="https://kartik-3004.github.io/portfolio/" target="_blank">Kartik
                                        Narayan*</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://vibashan.github.io/" target="_blank">Vibashan VS*</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=L60tuywAAAAJ&hl=en"
                                        target="_blank">Rama Chellappa</a>,
                                </span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en"
                                        target="_blank">Vishal M. Patel</a>
                                </span>
                            </div>
                        </div>


                        <div class="is-size-5 publication-authors">
                            <span class="author-block">Johns Hopkins University</span>
                        </div>

                        <div class="column has-text-centered">
                            <a href="as"></a>
                            </span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2403.12960"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/Kartik-3004/facexformer"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">

                    <h2 class="title is-3">Motivation & Contribution</h2>
                    <img src="./static/images/intro.png" alt="" border="0" height="600" width="1500">
                    <img src="./static/images/intro_table.png" alt="" style="border:0; height:1200px; width:1500px;">
                    <div class="content has-text-justified">
                        <p>Comparison with representative methods under different task settings.
                            <i>FaceXformer</i>
                            can perform various facial analysis tasks in single model. FP - Face Parsing, LD - Land-
                            marks Detection, HPE - Head Pose Estimation, Attr - Attributes
                            Recognition, Age - Age, Gen - Gender, Race - Race Estimation,
                            Exp - Facial Expression Recognition, and Vis - Face Visibility
                        </p>
                        <ul>
                            <li>
                                In recent years, significant advancements have been made in facial analysis, developing
                                state-of-the-art methods for
                                various tasks. Despite these methods achieving promising performance, they cannot be
                                integrated into a single pipeline due to their
                                specialized model designs and task-specific pre-processing techniques.
                            </li>
                            <li> <i>FaceXformer</i> is an end-to-end unified model capable of handling a comprehensive
                                range of facial analysis tasks such as face parsing, landmark detection, head pose
                                estimation, attributes prediction, and estimation of age, gender, race, epxression and
                                face
                                visibility.
                            </li>
                            <li> It leverages a transformer-based encoder-decoder architecture where
                                each task is treated as a learnable token, enabling the integration of multiple tasks
                                within a single framework.
                            </li>
                            <li> It effectively handles images "in-the-wild," demonstrating its robustness and
                                generalizability across eight heterogenous tasks, all while maintaining the real-time
                                performance of 33.21 FPS.</li>
                        </ul>

                        </p>
                    </div>
                </div>
            </div>

            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3"><i>FaceXformer</i> Framework</h2>
                            <div class="content has-text-justified">
                                <h5 class="subtitle has-text-centered"></h5>

                                <img src="./static/images/main_archi.png" alt="" border=0 height=500 width=1500></img>
                                <p>
                                    Overview of <i>FaceXformer</i> framework. It employs an encoder-decoder
                                    architecture, extracting multi-scale features from the input face image <b>I</b>,
                                    and
                                    fusing them into a unified representation <b>F</b> via MLP-Fusion. Task tokens
                                    <b>T</b>
                                    are processed alongside face representation <b>F</b> in the decoder, resulting in
                                    refined
                                    task-specific tokens <b><span style="position: relative; display: inline-block;">
                                            T
                                            <span
                                                style="position: absolute; top: -7px; left: 0.6px; right: 0; font-size: smaller;">^</span>
                                        </span></b>. These refined tokens are then used for
                                    task-specific predictions by passing through the unified head.
                                </p>


                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Quantitative Results</h2>
                            <div class="content has-text-justified">
                                <h5 class="subtitle has-text-centered"></h5>
                                <img src="./static/images/parsing.png" alt="" border=0 height=500 width=1500></img>
                                <p>
                                    Comparison with specialized models and existing multi-task networks on Face Parsing.
                                </p>
                            </div>
                        </div>
                    </div>
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <div class="content has-text-justified">
                                <h5 class="subtitle has-text-centered"></h5>
                                <img src="./static/images/hpe_lnd_attr.png" alt="" border=0 height=500 width=1500></img>
                                <p>
                                    Comparison with specialized models and existing multi-task networks on Headpose
                                    Estimation,
                                    Landmarks Detection and Attributes Prediction.
                                </p>
                            </div>
                        </div>
                    </div>
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <div class="content has-text-justified">
                                <h5 class="subtitle has-text-centered"></h5>
                                <img src="./static/images/results_others.png" alt="" border=0 height=500
                                    width=1500></img>
                                <p>
                                    Comparison with specialized models and existing multi-task networks on Facial
                                    Expression
                                    Recognition, Face Visibilty, and Age Estimation.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
        </div>
    </section>
    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Qualitative Results</h2>
                    <div class="content has-text-justified">
                        <h5 class="subtitle has-text-centered"></h5>
                        <img src="./static/images/qualitative.png" alt="" border=0 height=500 width=1500></img>
                        <p>
                            Qualitative results of <i>FaceXFormer</i>
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section" id="BibTeX">
        <div class="container content is-max-desktop">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{narayan2024facexformer,
    title={FaceXFormer: A Unified Transformer for Facial Analysis},
    author={Narayan, Kartik and VS, Vibashan and Chellappa, Rama and Patel, Vishal M},
    journal={arXiv preprint arXiv:2403.12960},
    year={2024}
}
</code></pre>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop content">
            <h5 class="title" style="font-size: 10px;"> Acknowledgement: The website template is taken from
                <span class="author-block">
                    <a href="https://nerfies.github.io/" target="_blank">Nerfies</a>
            </h5>

        </div>
    </section>

    <script>
        const viewers = document.querySelectorAll(".image-compare");
        viewers.forEach((element) => {
            let view = new ImageCompare(element, {
                hoverStart: true,
                addCircle: true
            }).mount();
        });

        $(document).ready(function () {
            var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
                lineNumbers: false,
                lineWrapping: true,
                readOnly: true
            });
            $(function () {
                $('[data-toggle="tooltip"]').tooltip()
            })
        });
    </script>
</body>

</html>